### LLM ###
save_model_path: "Meta-Llama-3-8B-Instruct"
model_id: "meta-llama/Meta-Llama-3-8B-Instruct"

system_prompt: "You are a helpful, respectful and friendly assistant. Always answer as helpfully as possible, while being safe. If you don't know the answer to a question, please don't share false information."

# prompt_template: """<|begin_of_text|>\n<|start_header_id|>system<|end_header_id|>{system}
# <|eot_id|>\n<|start_header_id|>user<|end_header_id|>{user}
# <|eot_id|>\n<|start_header_id|>assistant<|end_header_id|><|eot_id|>"""

prompt_template: "<|begin_of_text|>\n<|start_system|>{system}<|end_system|>\n<|start_user|>{user}<|end_user|>\n<|start_assistant|>"

temperature: 0
max_length: 300
min_length: 50
temperature: 0.1
top_k: 50
top_p: 0.9
early_stopping: true


### utils ###
logging_config_path: "../conf/base/logging.yaml"
setup_mlflow: false
mlflow_autolog: false
mlflow_tracking_uri: ""
mlflow_exp_name: "experiment-01"